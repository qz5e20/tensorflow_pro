{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d46ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Flatten\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5eb73",
   "metadata": {},
   "source": [
    "### 第1步：下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c58cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5795fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考API：https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file\n",
    "\n",
    "dataset_dir = tf.keras.utils.get_file(\"aclImdb\", origin=url, cache_dir='./IMDB', untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201a5cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./IMDB/datasets/aclImdb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07b1bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./IMDB/datasets/aclImdb/train'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9413ec6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urls_pos.txt',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'urls_unsup.txt',\n",
       " 'urls_neg.txt',\n",
       " 'labeledBow.feat',\n",
       " 'unsupBow.feat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd792a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理unsup文件夹\n",
    "\n",
    "# remove_dir = os.path.join(train_dir, 'unsup')\n",
    "\n",
    "# shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec85e3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urls_pos.txt',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'urls_unsup.txt',\n",
       " 'urls_neg.txt',\n",
       " 'labeledBow.feat',\n",
       " 'unsupBow.feat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5785b24",
   "metadata": {},
   "source": [
    "### 第2步：数据集分离"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742346a",
   "metadata": {},
   "source": [
    "#### 方式1：基于tensorflow API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3bf83ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    }
   ],
   "source": [
    "# 参考 API : https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text_dataset_from_directory\n",
    "\n",
    "BATCH_SIZE = 256 # 一批数据的大小\n",
    "SEED = 666 # 随机种子\n",
    "\n",
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(train_dir,\n",
    "                                                              batch_size=BATCH_SIZE,\n",
    "                                                              validation_split=0.2,\n",
    "                                                              subset='training',\n",
    "                                                              seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7661c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(train_dir,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            validation_split=0.2,\n",
    "                                                            subset='validation',\n",
    "                                                            seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "725e1f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 b\"I love this movie, Jouvet, Arletty, Blier, Carn\\xc3\\xa9... almost everything has already been said about the movie, but there is one detail I'd like to shed some light onto: no footage of the real, still standing, H\\xc3\\xb4tel du Nord (is it still? I heard it was to be demolished...) has been used for the movie - the whole scene has been rebuilt on set, the main reason being that they could not stop the traffic on the St Martin canal for several weeks.\"\n",
      "1 b'Brazilian films often get more positive appraisals than they actually deserve. Rather incredibly, Contra Todos (Against Everybody) (original title, which the producers discarded: God Against Everybody) got very low GPA (grade point average) in this website. It seems to be bluntly rejected by female spectators at large. Actually, it is not so brutal. I mean as far as graphical violence is concerned. Its brutality is intrinsic as it portrays would-be lumpens, I mean underdog citizens who in fact possess high-tech equipment, who coldly perform murder orders in exchange of \"grana gra\\xc3\\xbada\". Is this post-modern man? Is his/her only worry a quick, almost impersonal, ultra permissive lay, amidst over satiating meals ? The picture is probably the best Brazilian film of 2004, so far. Its shining editing style, \\xc3\\xa0 la Godard, its curious soundtrack counterpoints, its more than efficient overall cast and, above all, its original narration, with subtle non-chronological hidden points that only come to light in the epilogue, deserve at least an 8 mark.'\n",
      "1 b\"I thought the kids in the movie were great. I deal with kids in that age group, and I thought their behaviors were very believable. I did have a problem with the reference to the private parts made by the 5-year old. I didn't think the comment was necessary and actually slightly lowered my opinion of the movie. <br /><br />I think Luke Benward is up and coming star. I would like to see more of him on the big screen. I enjoyed his reactions to the situations that he found himself in. Often kids in this age group do things without thinking through the consequences. Almost all of the actors did this throughout the movie.<br /><br />I also think the message of bullying needs to be examined more in movies with this age group. It is a major problem in schools today.<br /><br />The ending was quite unexpected. Billy's thoughts on whether he won or didn't win the bet were very surprising. How he handled that situation was excellent. Too often today kids are not willing to compromise. The actors in this movie showed that compromise is an important part of life.\"\n",
      "0 b'This isn\\'t cinema. It isn\\'t talent. It isn\\'t informative. It isn\\'t scary. It isn\\'t entertaining. It isn\\'t anything at all.<br /><br />I got this because my cousin says, \"Diablo! COOL!\" Yeah, right. The only thing cool about this experience was the lone fact that I didn\\'t buy it but rented it instead.<br /><br />It\\'s shot like a bad soap opera. No wait. Soap operas at least LOOK professional...sorta. This? This looks like it was shot with someone\\'s camcorder. It\\'s horrid! Wretched! It sux.<br /><br />The cinematography is detestable! WHO IS this director anyway? I don\\'t even care enough to look him up. He STINKS! The performances by these poor unsuspecting actors were far better than this crap-fest deserved.<br /><br />2.6/10 on the \"B\" scale. <br /><br />That registers about a 0.3/10 on the \"A\" scale from...<br /><br />the Fiend :.'\n",
      "1 b'All right, here\\'s the deal: if you\\'re easily offended then you might want to stay far, far away from this one. There are some painfully funny moments in the movie, but I probably blushed about as much as I laughed. Actually, I probably blushed MORE than I laughed. And if I wasn\\'t literally blushing on the outside, then I was blushing on the inside. If there is absolutely nothing in this movie that embarrasses you then you simply have no shame. Whether that\\'s a badge of honor or not is in the eye of the beholder I suppose.<br /><br />I will not deny that I laughed quite a bit, but this is a movie that I simply cannot give a blanket recommendation due to its subject matter. If I were to say, \"This movie is hilarious, go check it out!\" and some sweet, little old church-going lady heads to the theater and has a heart-attack during one of the graphically explicit sex situations, well, that\\'s just something I don\\'t need on my conscience.<br /><br />So how raunchy is it? Hmm, try about 100 times worse than The Wedding Crashers. Honestly. My mom would\\'ve walked out during the first scene. I feel it\\'s my duty to at least warn you of what to expect.<br /><br />There is some cleverly intelligent comedy here, but that\\'s what I come to expect from the man (Judd Apatow) who had a hand in both Freaks and Geeks and Undeclared. I\\'m all for making fun of Michael McDonald; the only man whose hair and beard are white enough to give Kenny Rogers a run for his money. Paul Rudd proclaiming, \"If I hear Ya Mo Be There one more time I\\'ll Ya Mo burn this place down,\" is hilarious, but it\\'s one of those things that the majority of the audience won\\'t appreciate.<br /><br />And when we see a quick 3-second flashback of Steve Carrell singing along to Cameo\\'s Word Up, I laughed for a good two minutes after the joke was over, whereas most everybody chuckled and then forgot about it.<br /><br />Strangely enough, despite the raunch, there\\'s an admirable moral to the story. The movie doesn\\'t portray Carrell as some freaky loser just because he\\'s a virgin. He\\'s really portrayed as a likable, admirable character. Sure, he\\'s a little weird. After all, he has a framed Asia poster, \"more videogames than an Asian kid,\" and a toy collection that features the Million Dollar Man\\'s BOSS, but we\\'re never led to believe that there\\'s actually anything wrong with the fact that he\\'s a virgin. As odd as it may seem, there\\'s a bit of an \"it\\'s OK to wait\" message.<br /><br />But man, oh man, please be warned that this pushes its R rating about as far as it can go. That was certainly Apatow\\'s intention. According to him, he just let some of the guys (particularly Rogen and Malco) improv and talk the way they normally talk, all in an effort to find lots of new ways to be dirty. If you can handle that or talk that way yourself, then you\\'ll love the movie.<br /><br />I\\'m not a big fan of excessive profanity and sex jokes. I find that subtle, clever humor is much more entertaining than about 200 uses of the f-word or fratboy sex discussions. But that\\'s me. Like I said, there are some absolutely hysterical moments here, but you have to ask yourself if they\\'re worth sitting through one of the most vulgar movies you\\'re likely to ever see at the theater. I just don\\'t know how interested most women will be in what\\'s discussed by men while playing poker. Honestly ladies, you might not want to know. If you\\'ve ever been curious why some girls think guys are gross, well, this gives you a good idea.<br /><br />There you go - my humble, honest take on what to expect. Be that your guide. It definitely should not be seen with your Sunday School class, mama, grandmama, any family members of the opposite sex, children of any age, or anybody who is easily offended by excessive profanity or explicit sex discussion. If you\\'d see it with any of the above then you apparently do not have any concept of what it means to be uncomfortable.'\n"
     ]
    }
   ],
   "source": [
    "# 显示一批数据中的前5个\n",
    "\n",
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(label_batch[i].numpy(), text_batch[i].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ea9a8",
   "metadata": {},
   "source": [
    "#### 方式2：手动实现数据集切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f6e7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./IMDB/datasets/aclImdb/train'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir # 训练集数据集所在路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f67d05e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urls_pos.txt',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'urls_unsup.txt',\n",
       " 'urls_neg.txt',\n",
       " 'labeledBow.feat',\n",
       " 'unsupBow.feat']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir) # 文件夹下的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a91fa1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别读取 neg和pos文件夹下的文本文件\n",
    "\n",
    "labels = ['pos', 'neg'] # 标签\n",
    "texts_list = [] # 保存每一个文本文件中的内容\n",
    "labels_list = [] # 保存每一个文本文件对应的标签\n",
    "\n",
    "for lb in labels:\n",
    "    dir_name = os.path.join(train_dir, lb) # neg 或 pos 的文件夹路径\n",
    "    # 循环读取neg或pos文件夹下的文本文件\n",
    "    for fname in os.listdir(dir_name):\n",
    "        # 判断读取的文本文件的后缀名是否为 .txt\n",
    "        if fname[-4:] == '.txt':\n",
    "            file_path = os.path.join(dir_name, fname) # 拼接路径，即文本文件的完整路径\n",
    "            # 打开文本文件，进行读取\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read() # 读取内容\n",
    "            # 保存到texts_list\n",
    "            texts_list.append(content)\n",
    "            # 保存该文本文件对应的标签到labels_list\n",
    "            if lb == 'pos':\n",
    "                labels_list.append(1)\n",
    "            else: # neg\n",
    "                labels_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a672fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计所有文本文件的数量\n",
    "\n",
    "len(texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fd0248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计所有标签的数量\n",
    "\n",
    "len(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19d1aac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15707,  8280,  6529,  6874, 13584,  6239,  2472, 11465,  4783,\n",
       "        6795])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打乱样本顺序\n",
    "\n",
    "dataset_size = len(texts_list) # 数据集大小\n",
    "\n",
    "indices = np.arange(dataset_size) # 生成样本对应的索引\n",
    "\n",
    "np.random.shuffle(indices) # 打乱顺序\n",
    "\n",
    "indices[:10] # 显示前10个索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86603b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据索引，打乱样本\n",
    "\n",
    "data = np.array(texts_list)[indices]\n",
    "\n",
    "labels = np.array(labels_list)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b7c24f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Action, violence, sex and coarse language are the things that the characters do during the whole movie. And everything they do is done without reason. Mark L. Lester is (un)known for his violent (without reason)movies (Commando, The Base). The story is weird but stupid. The actors play their stupid characters very well...I'm not telling they are stupid but I mean they are very bad actors. It's another low-budget unknown B series action movie. If you saw something like Operation Delta Force, Drive, The Patriot, Sanctuary or something like these bad movies from the same kind than Misbegotten...don't rent it...and, by the way, don't rent any of the movies I mentioned....I give it 1and a half out of5.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一个样本\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a93f8e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a1352c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Eddie Murphy Delirious is by far the funniest thing you will ever see in your life. You can compare it to any movie, and I garuntee you will decide that Delirious is the funniest movie ever! This movie is about 1hr. 45 mins., and throughout that time, there was barely a moment where I wasn't laughing. You will laugh for hours after it is over, replaying the punch lines over and over and over in your head. Eddie Murphy has given so many funny performances over his career (48 Hrs.,Trading Places,Beverly Hills Cop,Raw,Coming To America, The Nutty professor,Shrek,etc.),but this is by far his MOST HILARIOUS moment. I have seen this movie so many times, and it is funnier every time. It never loses its edge. From this day forward, every great stand up performance will be emulated from Delirious. ***** and two thumbs up!\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二个样本\n",
    "\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f31b9744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16917353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集分离成 train 和 test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aabd4feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a67cac9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a936c3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff4310c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e45ca3c",
   "metadata": {},
   "source": [
    "### 第3步：数据加载到内存，提高I/O效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97d727b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84e944",
   "metadata": {},
   "source": [
    "### 第4步：数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f69bb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考 API ： https://www.tensorflow.org/api_docs/python/tf/strings/regex_replace\n",
    "\n",
    "def preprocessing(input_data):\n",
    "    # 所有字符串全部转换为小写\n",
    "    lower_string = tf.strings.lower(input_data)\n",
    "    # 用 ' ' 替换 '<br />'\n",
    "    new_string = tf.strings.regex_replace(lower_string, '<br />', ' ')\n",
    "    # 剔除字符串所有标点符号等，通过string.punctuation获取，用空字符替代\n",
    "    final_string = tf.strings.regex_replace(new_string, '[%s]'%re.escape(string.punctuation), '')\n",
    "    # 返回\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b8cf05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11481d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.escape(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82511f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考 API ： https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization\n",
    "\n",
    "# 单词的数量\n",
    "VOCAB_SIZE = 20000\n",
    "\n",
    "# 序列长度\n",
    "SEQ_LEN = 100\n",
    "\n",
    "# 对数据集进行预处理\n",
    "vectorize_layer = TextVectorization(standardize = preprocessing, # 标准化处理\n",
    "                                    max_tokens = VOCAB_SIZE, # 最大单词量\n",
    "                                    output_mode = 'int', # 每个word对应一个整型索引\n",
    "                                    output_sequence_length = SEQ_LEN # 输出序列的长度\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84099a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接下来针对文本数据进行预处理（注意：不是标签集）\n",
    "\n",
    "text_ds = train_ds.map(lambda x, y : x) # 仅仅选择文本数据\n",
    "\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c4e359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取一个batch_size的样本数据\n",
    "\n",
    "text_batch, label_batch = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f851da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从batch_size中获取一个sample\n",
    "\n",
    "text, label = text_batch[0], label_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0664dfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'FORBIDDEN PLANET is the best SF film from the golden age of SF cinema and what makes it a great film is its sense of wonder . As soon as the spaceship lands the audience - via the ships human crew - travels through an intelligent and sometimes terrifying adventure . We meet the unforgetable Robbie , the mysterious Dr Morbuis , his beautiful and innocent daughter Altair and we learn about the former inhabitants of the planet - The Krell who died out overnight . Or did they ? <br /><br />You can nitpick and say the planet is obviously filmed in a movie studio with painted backdrops but that adds to a sense of menace of claustraphobia I feel and Bebe and Louis Barron`s electronic music adds even more atmosphere <br /><br />I`m shocked this film isn`t in the top 250 IMDB films .'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ba671a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce179bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
       "array([[ 3687,  1165,     7,     2,   114,  6816,    19,    36,     2,\n",
       "         1924,   563,     5,  6816,   427,     3,    48,   159,     9,\n",
       "            4,    84,    19,     7,    29,   276,     5,   577,    14,\n",
       "          510,    14,     2,  7871,  5269,     2,   302,  2790,     2,\n",
       "         3996,   402,  1001,  4033,   138,    33,  1112,     3,   505,\n",
       "         3130,  1217,    71,   901,     2,     1, 12103,     2,  1278,\n",
       "          892,     1,    24,   290,     3,  1254,   589,     1,     3,\n",
       "           71,   814,    42,     2,  1124,  5708,     5,     2,  1165,\n",
       "            2, 10141,    35,  1109,    45, 10093,    40,   113,    34,\n",
       "           22,    68, 13704,     3,   131,     2,  1165,     7,   531,\n",
       "          772,     8,     4,    17,  1144,    15,  4446,  7995,    18,\n",
       "           12]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer(tf.expand_dims(text, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ab444",
   "metadata": {},
   "source": [
    "### 第5步：模型搭建、编译、训练、验证、预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4be5e",
   "metadata": {},
   "source": [
    "#### 方式1： 独立搭建模型训练、验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "def3581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding的维度\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential([\n",
    "    vectorize_layer, # 首先，对strings进行转换\n",
    "    Embedding(VOCAB_SIZE, embedding_dim, name='embedding'), # 通过training学习每个word的embedding vector\n",
    "    GlobalAveragePooling1D(), # 统一固定的输出vector，也可以用 Flatten()\n",
    "    Dense(32, activation='relu'), # 全连接层\n",
    "    Dense(1) # 输出1个值（neg 或 pos）\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cf73d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型编译\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), # loss='binary_crossentropy'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb4ebd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 tensorboard callback\n",
    "\n",
    "!rm -rf log_file # 如果存在log_file文件夹，则先删除\n",
    "\n",
    "log_file = os.path.join('log_file', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "568cd38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 3s 28ms/step - loss: 0.6597 - accuracy: 0.5121 - val_loss: 0.5824 - val_accuracy: 0.6246\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.4670 - accuracy: 0.7697 - val_loss: 0.4148 - val_accuracy: 0.7972\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.3227 - accuracy: 0.8598 - val_loss: 0.3727 - val_accuracy: 0.8272\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.2488 - accuracy: 0.8970 - val_loss: 0.3669 - val_accuracy: 0.8364\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.1977 - accuracy: 0.9233 - val_loss: 0.3780 - val_accuracy: 0.8344\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.1580 - accuracy: 0.9428 - val_loss: 0.3997 - val_accuracy: 0.8352\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.1258 - accuracy: 0.9575 - val_loss: 0.4292 - val_accuracy: 0.8334\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0989 - accuracy: 0.9694 - val_loss: 0.4657 - val_accuracy: 0.8314\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0765 - accuracy: 0.9788 - val_loss: 0.5072 - val_accuracy: 0.8304\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.0583 - accuracy: 0.9865 - val_loss: 0.5520 - val_accuracy: 0.8260\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0443 - accuracy: 0.9922 - val_loss: 0.5993 - val_accuracy: 0.8246\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0341 - accuracy: 0.9954 - val_loss: 0.6482 - val_accuracy: 0.8210\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0275 - accuracy: 0.9968 - val_loss: 0.6856 - val_accuracy: 0.8202\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0230 - accuracy: 0.9973 - val_loss: 0.7358 - val_accuracy: 0.8218\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0199 - accuracy: 0.9978 - val_loss: 0.7855 - val_accuracy: 0.8192\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0175 - accuracy: 0.9981 - val_loss: 0.8137 - val_accuracy: 0.8152\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0153 - accuracy: 0.9980 - val_loss: 0.8933 - val_accuracy: 0.8024\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0142 - accuracy: 0.9984 - val_loss: 0.9448 - val_accuracy: 0.7980\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 1.0412 - val_accuracy: 0.7846\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.9428 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabac223c70>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "\n",
    "model.fit(train_ds, # 训练集\n",
    "          validation_data=val_ds, # 验证集\n",
    "          epochs=20, # 训练轮数\n",
    "          callbacks=[tensorboard_callback]) # 保存训练日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3b044c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d8c276fda825508\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d8c276fda825508\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 显示训练和验证效果\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79c55bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 12ms/step - loss: 0.9428 - accuracy: 0.8140\n"
     ]
    }
   ],
   "source": [
    "# 模型验证\n",
    "\n",
    "loss, accuracy = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32b1a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.9428325891494751\n",
      "accuracy =  0.8140000104904175\n"
     ]
    }
   ],
   "source": [
    "print(\"loss = \", loss)\n",
    "print(\"accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "362a8de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93476254],\n",
       "       [-1.300469  ],\n",
       "       [-3.523317  ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型预测\n",
    "\n",
    "# 样本\n",
    "examples = [\n",
    "  \"The movie was great!\",\n",
    "  \"The movie was okay.\",\n",
    "  \"The movie was terrible...\"\n",
    "]\n",
    "\n",
    "model.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9da037",
   "metadata": {},
   "source": [
    "### 方式2：基于Glove预训练word embedding搭建模型，训练、验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13270e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './glove.6B/glove.6B.100d.txt' # 文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7c21866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开读取文件\n",
    "\n",
    "embedding_dicts = {}\n",
    "\n",
    "with open(glove_path, 'r') as file:\n",
    "    temp = file.read().split('\\n') # 按照换行符切分\n",
    "    for t in temp:\n",
    "        sentence = t.split(' ') # 每一行数据按照空格切分\n",
    "        word = sentence[0] # 第一个是word\n",
    "        coefs = sentence[1:] # 剩余部分为embedding数值\n",
    "        embedding_dicts[word] = coefs # 键 ：值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d43bcc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400001"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计字典中的元素个数\n",
    "\n",
    "len(embedding_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38cffc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key :  the\n",
      "value :  ['-0.038194', '-0.24487', '0.72812', '-0.39961', '0.083172', '0.043953', '-0.39141', '0.3344', '-0.57545', '0.087459', '0.28787', '-0.06731', '0.30906', '-0.26384', '-0.13231', '-0.20757', '0.33395', '-0.33848', '-0.31743', '-0.48336', '0.1464', '-0.37304', '0.34577', '0.052041', '0.44946', '-0.46971', '0.02628', '-0.54155', '-0.15518', '-0.14107', '-0.039722', '0.28277', '0.14393', '0.23464', '-0.31021', '0.086173', '0.20397', '0.52624', '0.17164', '-0.082378', '-0.71787', '-0.41531', '0.20335', '-0.12763', '0.41367', '0.55187', '0.57908', '-0.33477', '-0.36559', '-0.54857', '-0.062892', '0.26584', '0.30205', '0.99775', '-0.80481', '-3.0243', '0.01254', '-0.36942', '2.2167', '0.72201', '-0.24978', '0.92136', '0.034514', '0.46745', '1.1079', '-0.19358', '-0.074575', '0.23353', '-0.052062', '-0.22044', '0.057162', '-0.15806', '-0.30798', '-0.41625', '0.37972', '0.15006', '-0.53212', '-0.2055', '-1.2526', '0.071624', '0.70565', '0.49744', '-0.42063', '0.26148', '-1.538', '-0.30223', '-0.073438', '-0.28312', '0.37104', '-0.25217', '0.016215', '-0.017099', '-0.38984', '0.87424', '-0.72569', '-0.51058', '-0.52028', '-0.1459', '0.8278', '0.27062']\n"
     ]
    }
   ],
   "source": [
    "# 查看第一个word及其embedding\n",
    "\n",
    "for k, v in embedding_dicts.items():\n",
    "    print(\"key : \", k)\n",
    "    print(\"value : \", v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "192141e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计原始text数据集中不同的单词\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for dt in data:\n",
    "    res = preprocessing(dt) # 数据预处理（清理）\n",
    "    # print(res.numpy().decode('utf-8')) # b'' 解码\n",
    "    new_data.append(res.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "745241cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "213a390f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'action violence sex and coarse language are the things that the characters do during the whole movie and everything they do is done without reason mark l lester is unknown for his violent without reasonmovies commando the base the story is weird but stupid the actors play their stupid characters very wellim not telling they are stupid but i mean they are very bad actors its another lowbudget unknown b series action movie if you saw something like operation delta force drive the patriot sanctuary or something like these bad movies from the same kind than misbegottendont rent itand by the way dont rent any of the movies i mentionedi give it 1and a half out of5'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一个样本\n",
    "\n",
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "086bd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对清理后的文本进行分词\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f1458b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'is': 6,\n",
       " 'in': 7,\n",
       " 'it': 8,\n",
       " 'i': 9,\n",
       " 'this': 10,\n",
       " 'that': 11,\n",
       " 'was': 12,\n",
       " 'as': 13,\n",
       " 'for': 14,\n",
       " 'with': 15,\n",
       " 'movie': 16,\n",
       " 'but': 17,\n",
       " 'film': 18,\n",
       " 'on': 19,\n",
       " 'not': 20,\n",
       " 'you': 21,\n",
       " 'are': 22,\n",
       " 'his': 23,\n",
       " 'have': 24,\n",
       " 'be': 25,\n",
       " 'he': 26,\n",
       " 'one': 27,\n",
       " 'its': 28,\n",
       " 'at': 29,\n",
       " 'all': 30,\n",
       " 'by': 31,\n",
       " 'an': 32,\n",
       " 'they': 33,\n",
       " 'from': 34,\n",
       " 'who': 35,\n",
       " 'so': 36,\n",
       " 'like': 37,\n",
       " 'her': 38,\n",
       " 'just': 39,\n",
       " 'or': 40,\n",
       " 'about': 41,\n",
       " 'has': 42,\n",
       " 'if': 43,\n",
       " 'out': 44,\n",
       " 'some': 45,\n",
       " 'there': 46,\n",
       " 'what': 47,\n",
       " 'good': 48,\n",
       " 'more': 49,\n",
       " 'when': 50,\n",
       " 'very': 51,\n",
       " 'even': 52,\n",
       " 'she': 53,\n",
       " 'my': 54,\n",
       " 'up': 55,\n",
       " 'no': 56,\n",
       " 'would': 57,\n",
       " 'time': 58,\n",
       " 'which': 59,\n",
       " 'only': 60,\n",
       " 'really': 61,\n",
       " 'story': 62,\n",
       " 'their': 63,\n",
       " 'were': 64,\n",
       " 'see': 65,\n",
       " 'had': 66,\n",
       " 'can': 67,\n",
       " 'me': 68,\n",
       " 'than': 69,\n",
       " 'we': 70,\n",
       " 'much': 71,\n",
       " 'well': 72,\n",
       " 'been': 73,\n",
       " 'get': 74,\n",
       " 'will': 75,\n",
       " 'also': 76,\n",
       " 'into': 77,\n",
       " 'bad': 78,\n",
       " 'other': 79,\n",
       " 'people': 80,\n",
       " 'do': 81,\n",
       " 'because': 82,\n",
       " 'great': 83,\n",
       " 'first': 84,\n",
       " 'how': 85,\n",
       " 'him': 86,\n",
       " 'most': 87,\n",
       " 'dont': 88,\n",
       " 'made': 89,\n",
       " 'then': 90,\n",
       " 'movies': 91,\n",
       " 'them': 92,\n",
       " 'way': 93,\n",
       " 'films': 94,\n",
       " 'make': 95,\n",
       " 'could': 96,\n",
       " 'too': 97,\n",
       " 'any': 98,\n",
       " 'after': 99,\n",
       " 'characters': 100,\n",
       " 'think': 101,\n",
       " 'watch': 102,\n",
       " 'two': 103,\n",
       " 'many': 104,\n",
       " 'seen': 105,\n",
       " 'character': 106,\n",
       " 'being': 107,\n",
       " 'never': 108,\n",
       " 'little': 109,\n",
       " 'acting': 110,\n",
       " 'plot': 111,\n",
       " 'best': 112,\n",
       " 'where': 113,\n",
       " 'love': 114,\n",
       " 'did': 115,\n",
       " 'life': 116,\n",
       " 'know': 117,\n",
       " 'show': 118,\n",
       " 'does': 119,\n",
       " 'ever': 120,\n",
       " 'better': 121,\n",
       " 'your': 122,\n",
       " 'still': 123,\n",
       " 'over': 124,\n",
       " 'end': 125,\n",
       " 'off': 126,\n",
       " 'here': 127,\n",
       " 'these': 128,\n",
       " 'say': 129,\n",
       " 'while': 130,\n",
       " 'scene': 131,\n",
       " 'man': 132,\n",
       " 'why': 133,\n",
       " 'scenes': 134,\n",
       " 'such': 135,\n",
       " 'go': 136,\n",
       " 'something': 137,\n",
       " 'should': 138,\n",
       " 'through': 139,\n",
       " 'back': 140,\n",
       " 'im': 141,\n",
       " 'those': 142,\n",
       " 'doesnt': 143,\n",
       " 'watching': 144,\n",
       " 'real': 145,\n",
       " 'years': 146,\n",
       " 'now': 147,\n",
       " 'though': 148,\n",
       " 'thing': 149,\n",
       " 'actors': 150,\n",
       " 'didnt': 151,\n",
       " 'another': 152,\n",
       " 'before': 153,\n",
       " 'new': 154,\n",
       " 'nothing': 155,\n",
       " 'actually': 156,\n",
       " 'work': 157,\n",
       " 'funny': 158,\n",
       " 'makes': 159,\n",
       " 'find': 160,\n",
       " 'look': 161,\n",
       " 'few': 162,\n",
       " 'old': 163,\n",
       " 'going': 164,\n",
       " 'same': 165,\n",
       " 'us': 166,\n",
       " 'every': 167,\n",
       " 'lot': 168,\n",
       " 'part': 169,\n",
       " 'again': 170,\n",
       " 'director': 171,\n",
       " 'cast': 172,\n",
       " 'thats': 173,\n",
       " 'cant': 174,\n",
       " 'quite': 175,\n",
       " 'want': 176,\n",
       " 'things': 177,\n",
       " 'pretty': 178,\n",
       " 'seems': 179,\n",
       " 'young': 180,\n",
       " 'got': 181,\n",
       " 'around': 182,\n",
       " 'world': 183,\n",
       " 'down': 184,\n",
       " 'fact': 185,\n",
       " 'however': 186,\n",
       " 'take': 187,\n",
       " 'enough': 188,\n",
       " 'both': 189,\n",
       " 'between': 190,\n",
       " 'give': 191,\n",
       " 'may': 192,\n",
       " 'horror': 193,\n",
       " 'big': 194,\n",
       " 'original': 195,\n",
       " 'ive': 196,\n",
       " 'own': 197,\n",
       " 'thought': 198,\n",
       " 'series': 199,\n",
       " 'without': 200,\n",
       " 'gets': 201,\n",
       " 'right': 202,\n",
       " 'always': 203,\n",
       " 'long': 204,\n",
       " 'times': 205,\n",
       " 'isnt': 206,\n",
       " 'come': 207,\n",
       " 'saw': 208,\n",
       " 'point': 209,\n",
       " 'role': 210,\n",
       " 'almost': 211,\n",
       " 'interesting': 212,\n",
       " 'action': 213,\n",
       " 'least': 214,\n",
       " 'theres': 215,\n",
       " 'whole': 216,\n",
       " 'comedy': 217,\n",
       " 'must': 218,\n",
       " 'family': 219,\n",
       " 'bit': 220,\n",
       " 'done': 221,\n",
       " 'music': 222,\n",
       " 'script': 223,\n",
       " 'minutes': 224,\n",
       " 'anything': 225,\n",
       " 'last': 226,\n",
       " 'might': 227,\n",
       " 'hes': 228,\n",
       " 'guy': 229,\n",
       " 'since': 230,\n",
       " 'feel': 231,\n",
       " 'performance': 232,\n",
       " 'far': 233,\n",
       " 'probably': 234,\n",
       " 'am': 235,\n",
       " 'kind': 236,\n",
       " 'rather': 237,\n",
       " 'away': 238,\n",
       " 'yet': 239,\n",
       " 'worst': 240,\n",
       " 'sure': 241,\n",
       " 'fun': 242,\n",
       " 'tv': 243,\n",
       " 'girl': 244,\n",
       " 'woman': 245,\n",
       " 'making': 246,\n",
       " 'each': 247,\n",
       " 'anyone': 248,\n",
       " 'found': 249,\n",
       " 'played': 250,\n",
       " 'having': 251,\n",
       " 'our': 252,\n",
       " 'although': 253,\n",
       " 'believe': 254,\n",
       " 'day': 255,\n",
       " 'course': 256,\n",
       " 'comes': 257,\n",
       " 'trying': 258,\n",
       " 'especially': 259,\n",
       " 'goes': 260,\n",
       " 'shows': 261,\n",
       " 'hard': 262,\n",
       " 'looks': 263,\n",
       " 'different': 264,\n",
       " 'place': 265,\n",
       " 'put': 266,\n",
       " 'wasnt': 267,\n",
       " 'book': 268,\n",
       " 'money': 269,\n",
       " 'ending': 270,\n",
       " 'sense': 271,\n",
       " 'reason': 272,\n",
       " 'once': 273,\n",
       " 'maybe': 274,\n",
       " 'everything': 275,\n",
       " 'true': 276,\n",
       " 'set': 277,\n",
       " 'screen': 278,\n",
       " 'worth': 279,\n",
       " 'main': 280,\n",
       " 'looking': 281,\n",
       " 'job': 282,\n",
       " 'someone': 283,\n",
       " 'watched': 284,\n",
       " 'plays': 285,\n",
       " 'actor': 286,\n",
       " '2': 287,\n",
       " 'together': 288,\n",
       " 'dvd': 289,\n",
       " 'said': 290,\n",
       " 'three': 291,\n",
       " 'later': 292,\n",
       " 'seem': 293,\n",
       " 'takes': 294,\n",
       " 'instead': 295,\n",
       " '10': 296,\n",
       " 'play': 297,\n",
       " 'beautiful': 298,\n",
       " 'himself': 299,\n",
       " 'effects': 300,\n",
       " 'john': 301,\n",
       " 'during': 302,\n",
       " 'version': 303,\n",
       " 'audience': 304,\n",
       " 'everyone': 305,\n",
       " 'left': 306,\n",
       " 'seeing': 307,\n",
       " 'night': 308,\n",
       " 'special': 309,\n",
       " 'house': 310,\n",
       " 'excellent': 311,\n",
       " 'idea': 312,\n",
       " 'american': 313,\n",
       " 'nice': 314,\n",
       " 'shot': 315,\n",
       " 'wife': 316,\n",
       " 'simply': 317,\n",
       " 'youre': 318,\n",
       " 'read': 319,\n",
       " 'else': 320,\n",
       " 'high': 321,\n",
       " 'less': 322,\n",
       " 'black': 323,\n",
       " 'kids': 324,\n",
       " 'help': 325,\n",
       " 'completely': 326,\n",
       " 'war': 327,\n",
       " 'second': 328,\n",
       " 'poor': 329,\n",
       " 'fan': 330,\n",
       " 'star': 331,\n",
       " 'year': 332,\n",
       " 'death': 333,\n",
       " 'used': 334,\n",
       " 'given': 335,\n",
       " 'father': 336,\n",
       " 'either': 337,\n",
       " 'friends': 338,\n",
       " 'mind': 339,\n",
       " 'home': 340,\n",
       " 'try': 341,\n",
       " 'men': 342,\n",
       " 'performances': 343,\n",
       " 'enjoy': 344,\n",
       " 'classic': 345,\n",
       " 'rest': 346,\n",
       " 'need': 347,\n",
       " 'short': 348,\n",
       " 'use': 349,\n",
       " 'boring': 350,\n",
       " 'wrong': 351,\n",
       " 'until': 352,\n",
       " 'along': 353,\n",
       " 'hollywood': 354,\n",
       " 'truly': 355,\n",
       " 'dead': 356,\n",
       " 'half': 357,\n",
       " 'production': 358,\n",
       " 'line': 359,\n",
       " 'tell': 360,\n",
       " 'women': 361,\n",
       " 'remember': 362,\n",
       " 'next': 363,\n",
       " 'couple': 364,\n",
       " 'start': 365,\n",
       " 'came': 366,\n",
       " 'recommend': 367,\n",
       " 'perhaps': 368,\n",
       " 'stupid': 369,\n",
       " 'others': 370,\n",
       " 'moments': 371,\n",
       " 'wonderful': 372,\n",
       " 'awful': 373,\n",
       " 'understand': 374,\n",
       " 'full': 375,\n",
       " 'let': 376,\n",
       " 'mean': 377,\n",
       " 'episode': 378,\n",
       " 'terrible': 379,\n",
       " 'getting': 380,\n",
       " 'stars': 381,\n",
       " 'camera': 382,\n",
       " 'playing': 383,\n",
       " 'keep': 384,\n",
       " 'doing': 385,\n",
       " 'often': 386,\n",
       " 'small': 387,\n",
       " 'sex': 388,\n",
       " 'definitely': 389,\n",
       " 'video': 390,\n",
       " 'gives': 391,\n",
       " 'perfect': 392,\n",
       " 'face': 393,\n",
       " 'early': 394,\n",
       " 'itself': 395,\n",
       " 'name': 396,\n",
       " 'become': 397,\n",
       " 'school': 398,\n",
       " 'lines': 399,\n",
       " 'finally': 400,\n",
       " 'human': 401,\n",
       " 'felt': 402,\n",
       " 'person': 403,\n",
       " 'dialogue': 404,\n",
       " 'supposed': 405,\n",
       " 'lost': 406,\n",
       " 'piece': 407,\n",
       " 'couldnt': 408,\n",
       " 'liked': 409,\n",
       " 'case': 410,\n",
       " 'top': 411,\n",
       " 'yes': 412,\n",
       " 'absolutely': 413,\n",
       " 'written': 414,\n",
       " 'title': 415,\n",
       " 'head': 416,\n",
       " 'against': 417,\n",
       " 'live': 418,\n",
       " 'budget': 419,\n",
       " 'entire': 420,\n",
       " 'went': 421,\n",
       " 'certainly': 422,\n",
       " 'waste': 423,\n",
       " 'sort': 424,\n",
       " 'picture': 425,\n",
       " 'style': 426,\n",
       " 'shes': 427,\n",
       " 'worse': 428,\n",
       " 'problem': 429,\n",
       " 'hope': 430,\n",
       " 'cinema': 431,\n",
       " 'evil': 432,\n",
       " 'entertaining': 433,\n",
       " 'overall': 434,\n",
       " 'several': 435,\n",
       " 'loved': 436,\n",
       " 'fans': 437,\n",
       " 'beginning': 438,\n",
       " 'mr': 439,\n",
       " 'id': 440,\n",
       " 'boy': 441,\n",
       " '3': 442,\n",
       " 'becomes': 443,\n",
       " 'care': 444,\n",
       " 'already': 445,\n",
       " 'lives': 446,\n",
       " 'white': 447,\n",
       " 'seemed': 448,\n",
       " 'throughout': 449,\n",
       " 'based': 450,\n",
       " 'example': 451,\n",
       " 'direction': 452,\n",
       " 'mother': 453,\n",
       " 'killer': 454,\n",
       " 'despite': 455,\n",
       " 'guys': 456,\n",
       " 'dark': 457,\n",
       " 'oh': 458,\n",
       " 'wanted': 459,\n",
       " '\\x96': 460,\n",
       " 'friend': 461,\n",
       " 'unfortunately': 462,\n",
       " 'final': 463,\n",
       " 'children': 464,\n",
       " 'turn': 465,\n",
       " '1': 466,\n",
       " 'fine': 467,\n",
       " 'drama': 468,\n",
       " 'laugh': 469,\n",
       " 'totally': 470,\n",
       " 'amazing': 471,\n",
       " 'wont': 472,\n",
       " 'wants': 473,\n",
       " 'girls': 474,\n",
       " 'guess': 475,\n",
       " 'history': 476,\n",
       " 'humor': 477,\n",
       " 'sound': 478,\n",
       " 'lead': 479,\n",
       " 'writing': 480,\n",
       " 'days': 481,\n",
       " 'youll': 482,\n",
       " 'low': 483,\n",
       " 'works': 484,\n",
       " 'tries': 485,\n",
       " 'called': 486,\n",
       " 'under': 487,\n",
       " 'michael': 488,\n",
       " 'past': 489,\n",
       " 'quality': 490,\n",
       " 'behind': 491,\n",
       " 'turns': 492,\n",
       " 'enjoyed': 493,\n",
       " 'able': 494,\n",
       " 'theyre': 495,\n",
       " 'game': 496,\n",
       " 'act': 497,\n",
       " 'favorite': 498,\n",
       " 'son': 499,\n",
       " 'starts': 500,\n",
       " 'gave': 501,\n",
       " 'kill': 502,\n",
       " 'flick': 503,\n",
       " 'eyes': 504,\n",
       " 'sometimes': 505,\n",
       " 'side': 506,\n",
       " 'viewer': 507,\n",
       " 'horrible': 508,\n",
       " 'town': 509,\n",
       " 'ones': 510,\n",
       " 'car': 511,\n",
       " 'soon': 512,\n",
       " 'parts': 513,\n",
       " 'actress': 514,\n",
       " 'child': 515,\n",
       " 'expect': 516,\n",
       " 'themselves': 517,\n",
       " 'brilliant': 518,\n",
       " 'heart': 519,\n",
       " 'art': 520,\n",
       " 'genre': 521,\n",
       " 'stuff': 522,\n",
       " 'obviously': 523,\n",
       " 'stories': 524,\n",
       " 'thinking': 525,\n",
       " 'directed': 526,\n",
       " 'late': 527,\n",
       " 'myself': 528,\n",
       " 'ill': 529,\n",
       " 'feeling': 530,\n",
       " 'run': 531,\n",
       " 'decent': 532,\n",
       " 'blood': 533,\n",
       " 'highly': 534,\n",
       " 'city': 535,\n",
       " 'close': 536,\n",
       " 'etc': 537,\n",
       " 'fight': 538,\n",
       " 'hand': 539,\n",
       " 'says': 540,\n",
       " 'heard': 541,\n",
       " 'matter': 542,\n",
       " 'roles': 543,\n",
       " 'took': 544,\n",
       " 'killed': 545,\n",
       " 'except': 546,\n",
       " 'moment': 547,\n",
       " 'cannot': 548,\n",
       " 'leave': 549,\n",
       " 'kid': 550,\n",
       " 'hell': 551,\n",
       " 'police': 552,\n",
       " 'anyway': 553,\n",
       " 'happens': 554,\n",
       " 'strong': 555,\n",
       " 'wouldnt': 556,\n",
       " 'hour': 557,\n",
       " 'happened': 558,\n",
       " 'extremely': 559,\n",
       " 'involved': 560,\n",
       " 'chance': 561,\n",
       " 'particularly': 562,\n",
       " 'obvious': 563,\n",
       " 'lack': 564,\n",
       " 'violence': 565,\n",
       " 'experience': 566,\n",
       " 'attempt': 567,\n",
       " 'told': 568,\n",
       " 'living': 569,\n",
       " 'james': 570,\n",
       " 'alone': 571,\n",
       " 'happen': 572,\n",
       " 'wonder': 573,\n",
       " 'age': 574,\n",
       " 'murder': 575,\n",
       " 'complete': 576,\n",
       " 'voice': 577,\n",
       " 'including': 578,\n",
       " 'ago': 579,\n",
       " 'daughter': 580,\n",
       " 'coming': 581,\n",
       " 'save': 582,\n",
       " 'please': 583,\n",
       " 'god': 584,\n",
       " 'group': 585,\n",
       " 'interest': 586,\n",
       " 'type': 587,\n",
       " 'score': 588,\n",
       " 'looked': 589,\n",
       " 'none': 590,\n",
       " 'ok': 591,\n",
       " 'simple': 592,\n",
       " 'number': 593,\n",
       " 'exactly': 594,\n",
       " 'slow': 595,\n",
       " 'shown': 596,\n",
       " 'brother': 597,\n",
       " 'possible': 598,\n",
       " 'crap': 599,\n",
       " 'lets': 600,\n",
       " 'annoying': 601,\n",
       " 'yourself': 602,\n",
       " 'career': 603,\n",
       " 'whose': 604,\n",
       " 'taken': 605,\n",
       " 'sad': 606,\n",
       " 'serious': 607,\n",
       " 'usually': 608,\n",
       " 'hours': 609,\n",
       " 'ends': 610,\n",
       " 'cinematography': 611,\n",
       " 'stop': 612,\n",
       " 'song': 613,\n",
       " 'across': 614,\n",
       " 'david': 615,\n",
       " 'seriously': 616,\n",
       " 'scary': 617,\n",
       " 'released': 618,\n",
       " 'running': 619,\n",
       " 'musical': 620,\n",
       " 'today': 621,\n",
       " 'gore': 622,\n",
       " 'somewhat': 623,\n",
       " 'opening': 624,\n",
       " 'known': 625,\n",
       " 'usual': 626,\n",
       " 'hilarious': 627,\n",
       " 'started': 628,\n",
       " 'relationship': 629,\n",
       " 'hit': 630,\n",
       " 'reality': 631,\n",
       " 'ridiculous': 632,\n",
       " 'jokes': 633,\n",
       " 'wish': 634,\n",
       " 'finds': 635,\n",
       " 'change': 636,\n",
       " 'cool': 637,\n",
       " 'huge': 638,\n",
       " 'order': 639,\n",
       " 'shots': 640,\n",
       " 'episodes': 641,\n",
       " 'saying': 642,\n",
       " 'opinion': 643,\n",
       " 'cut': 644,\n",
       " 'english': 645,\n",
       " 'body': 646,\n",
       " 'novel': 647,\n",
       " 'mostly': 648,\n",
       " 'robert': 649,\n",
       " 'taking': 650,\n",
       " 'major': 651,\n",
       " 'talking': 652,\n",
       " 'female': 653,\n",
       " '4': 654,\n",
       " 'hero': 655,\n",
       " 'call': 656,\n",
       " 'power': 657,\n",
       " 'strange': 658,\n",
       " 'view': 659,\n",
       " 'apparently': 660,\n",
       " 'level': 661,\n",
       " 'disappointed': 662,\n",
       " 'directors': 663,\n",
       " 'talent': 664,\n",
       " 'happy': 665,\n",
       " '5': 666,\n",
       " 'documentary': 667,\n",
       " 'due': 668,\n",
       " 'important': 669,\n",
       " 'events': 670,\n",
       " 'basically': 671,\n",
       " 'husband': 672,\n",
       " 'room': 673,\n",
       " 'knows': 674,\n",
       " 'songs': 675,\n",
       " 'clearly': 676,\n",
       " 'supporting': 677,\n",
       " 'knew': 678,\n",
       " 'king': 679,\n",
       " 'turned': 680,\n",
       " 'rating': 681,\n",
       " 'attention': 682,\n",
       " 'arent': 683,\n",
       " 'easily': 684,\n",
       " 'british': 685,\n",
       " 'problems': 686,\n",
       " 'tells': 687,\n",
       " 'single': 688,\n",
       " 'local': 689,\n",
       " 'future': 690,\n",
       " 'silly': 691,\n",
       " 'television': 692,\n",
       " 'word': 693,\n",
       " 'words': 694,\n",
       " 'cheap': 695,\n",
       " 'bring': 696,\n",
       " 'country': 697,\n",
       " 'sequence': 698,\n",
       " 'light': 699,\n",
       " 'four': 700,\n",
       " 'modern': 701,\n",
       " 'beyond': 702,\n",
       " 'whats': 703,\n",
       " 'earth': 704,\n",
       " 'whether': 705,\n",
       " 'sets': 706,\n",
       " 'miss': 707,\n",
       " 'jack': 708,\n",
       " 'five': 709,\n",
       " 'entertainment': 710,\n",
       " 'falls': 711,\n",
       " 'viewers': 712,\n",
       " 'similar': 713,\n",
       " 'paul': 714,\n",
       " 'review': 715,\n",
       " 'predictable': 716,\n",
       " 'needs': 717,\n",
       " 'appears': 718,\n",
       " 'upon': 719,\n",
       " 'enjoyable': 720,\n",
       " 'romantic': 721,\n",
       " 'giving': 722,\n",
       " 'comic': 723,\n",
       " 'richard': 724,\n",
       " 'george': 725,\n",
       " 'talk': 726,\n",
       " 'within': 727,\n",
       " 'storyline': 728,\n",
       " 'message': 729,\n",
       " 'animation': 730,\n",
       " 'theater': 731,\n",
       " 'havent': 732,\n",
       " 'feels': 733,\n",
       " 'mention': 734,\n",
       " 'bunch': 735,\n",
       " 'nearly': 736,\n",
       " 'rock': 737,\n",
       " 'lady': 738,\n",
       " 'add': 739,\n",
       " 'sequel': 740,\n",
       " 'points': 741,\n",
       " 'above': 742,\n",
       " 'mystery': 743,\n",
       " 'moving': 744,\n",
       " 'surprised': 745,\n",
       " 'herself': 746,\n",
       " 'lots': 747,\n",
       " 'dull': 748,\n",
       " 'ways': 749,\n",
       " 'theme': 750,\n",
       " 'begins': 751,\n",
       " 'using': 752,\n",
       " 'actual': 753,\n",
       " 'middle': 754,\n",
       " 'ten': 755,\n",
       " 'named': 756,\n",
       " 'effort': 757,\n",
       " 'fantastic': 758,\n",
       " 'writer': 759,\n",
       " 'thriller': 760,\n",
       " 'among': 761,\n",
       " 'comments': 762,\n",
       " 'york': 763,\n",
       " 'easy': 764,\n",
       " 'elements': 765,\n",
       " 'stay': 766,\n",
       " 'showing': 767,\n",
       " 'typical': 768,\n",
       " 'team': 769,\n",
       " 'clear': 770,\n",
       " 'release': 771,\n",
       " 'tried': 772,\n",
       " 'certain': 773,\n",
       " 'avoid': 774,\n",
       " 'dialog': 775,\n",
       " 'fall': 776,\n",
       " 'french': 777,\n",
       " 'parents': 778,\n",
       " 'tale': 779,\n",
       " 'near': 780,\n",
       " 'hate': 781,\n",
       " 'soundtrack': 782,\n",
       " 'means': 783,\n",
       " 'season': 784,\n",
       " 'famous': 785,\n",
       " 'straight': 786,\n",
       " 'editing': 787,\n",
       " 'somehow': 788,\n",
       " 'sorry': 789,\n",
       " 'leads': 790,\n",
       " 'working': 791,\n",
       " 'class': 792,\n",
       " 'form': 793,\n",
       " 'general': 794,\n",
       " 'material': 795,\n",
       " 'buy': 796,\n",
       " 'red': 797,\n",
       " 'peter': 798,\n",
       " 'doubt': 799,\n",
       " 'kept': 800,\n",
       " 'check': 801,\n",
       " 'greatest': 802,\n",
       " 'filmed': 803,\n",
       " 'sister': 804,\n",
       " 'figure': 805,\n",
       " 'weak': 806,\n",
       " 'viewing': 807,\n",
       " 'oscar': 808,\n",
       " 'tom': 809,\n",
       " 'feature': 810,\n",
       " 'period': 811,\n",
       " 'brought': 812,\n",
       " 'gone': 813,\n",
       " 'eye': 814,\n",
       " 'hear': 815,\n",
       " 'particular': 816,\n",
       " 'imagine': 817,\n",
       " 'realistic': 818,\n",
       " 'whos': 819,\n",
       " 'atmosphere': 820,\n",
       " 'fast': 821,\n",
       " 'follow': 822,\n",
       " 'learn': 823,\n",
       " 'lame': 824,\n",
       " 'move': 825,\n",
       " 'reviews': 826,\n",
       " 'sequences': 827,\n",
       " 'eventually': 828,\n",
       " 'indeed': 829,\n",
       " 'forget': 830,\n",
       " 'youve': 831,\n",
       " 'die': 832,\n",
       " 'deal': 833,\n",
       " 'premise': 834,\n",
       " 'space': 835,\n",
       " 'dance': 836,\n",
       " 'decided': 837,\n",
       " 'believable': 838,\n",
       " 'lee': 839,\n",
       " 'possibly': 840,\n",
       " 'crime': 841,\n",
       " 'wait': 842,\n",
       " 'surprise': 843,\n",
       " 'expected': 844,\n",
       " 'third': 845,\n",
       " 'became': 846,\n",
       " 'whatever': 847,\n",
       " 'de': 848,\n",
       " 'suspense': 849,\n",
       " 'stand': 850,\n",
       " 'nature': 851,\n",
       " 'difficult': 852,\n",
       " 'japanese': 853,\n",
       " 'zombie': 854,\n",
       " 'sit': 855,\n",
       " 'poorly': 856,\n",
       " 'sexual': 857,\n",
       " 'writers': 858,\n",
       " 'okay': 859,\n",
       " 'truth': 860,\n",
       " 'average': 861,\n",
       " 'subject': 862,\n",
       " '80s': 863,\n",
       " 'leaves': 864,\n",
       " 'rent': 865,\n",
       " 'screenplay': 866,\n",
       " 'nor': 867,\n",
       " 'stage': 868,\n",
       " 'needed': 869,\n",
       " 'romance': 870,\n",
       " 'killing': 871,\n",
       " 'begin': 872,\n",
       " 'filmmakers': 873,\n",
       " 'reading': 874,\n",
       " 'question': 875,\n",
       " 'note': 876,\n",
       " 'situation': 877,\n",
       " 'meet': 878,\n",
       " 'boys': 879,\n",
       " 'dr': 880,\n",
       " 'memorable': 881,\n",
       " 'meets': 882,\n",
       " 'superb': 883,\n",
       " 'street': 884,\n",
       " 'shame': 885,\n",
       " 'otherwise': 886,\n",
       " 'credits': 887,\n",
       " 'forced': 888,\n",
       " 'joe': 889,\n",
       " 'earlier': 890,\n",
       " 'minute': 891,\n",
       " 'emotional': 892,\n",
       " 'realize': 893,\n",
       " 'unless': 894,\n",
       " 'baby': 895,\n",
       " 'weird': 896,\n",
       " 'footage': 897,\n",
       " 'older': 898,\n",
       " 'beauty': 899,\n",
       " 'interested': 900,\n",
       " 'disney': 901,\n",
       " 'write': 902,\n",
       " 'society': 903,\n",
       " 'keeps': 904,\n",
       " 'badly': 905,\n",
       " 'comment': 906,\n",
       " 'whom': 907,\n",
       " 'laughs': 908,\n",
       " 'dramatic': 909,\n",
       " 'features': 910,\n",
       " 'dog': 911,\n",
       " 'ask': 912,\n",
       " 'hot': 913,\n",
       " 'towards': 914,\n",
       " 'sounds': 915,\n",
       " 'america': 916,\n",
       " 'crazy': 917,\n",
       " 'development': 918,\n",
       " 'mess': 919,\n",
       " 'quickly': 920,\n",
       " 'total': 921,\n",
       " 'perfectly': 922,\n",
       " 'brings': 923,\n",
       " 'previous': 924,\n",
       " 'result': 925,\n",
       " 'directing': 926,\n",
       " 'male': 927,\n",
       " 'unique': 928,\n",
       " 'plenty': 929,\n",
       " 'worked': 930,\n",
       " 'personal': 931,\n",
       " 'free': 932,\n",
       " 'plus': 933,\n",
       " 'effect': 934,\n",
       " 'creepy': 935,\n",
       " 'incredibly': 936,\n",
       " 'hands': 937,\n",
       " 'imdb': 938,\n",
       " 'cheesy': 939,\n",
       " 'mark': 940,\n",
       " 'deep': 941,\n",
       " 'admit': 942,\n",
       " 'return': 943,\n",
       " 'apart': 944,\n",
       " 'appear': 945,\n",
       " 'setting': 946,\n",
       " 'brothers': 947,\n",
       " 'b': 948,\n",
       " 'meant': 949,\n",
       " 'open': 950,\n",
       " 'hardly': 951,\n",
       " 'leading': 952,\n",
       " 'casting': 953,\n",
       " 'background': 954,\n",
       " 'dream': 955,\n",
       " 'christmas': 956,\n",
       " '20': 957,\n",
       " 'remake': 958,\n",
       " 'potential': 959,\n",
       " 'various': 960,\n",
       " 'powerful': 961,\n",
       " 'create': 962,\n",
       " 'forward': 963,\n",
       " 'fails': 964,\n",
       " 'scifi': 965,\n",
       " 'battle': 966,\n",
       " 'business': 967,\n",
       " 'monster': 968,\n",
       " 'bill': 969,\n",
       " 'inside': 970,\n",
       " 'portrayed': 971,\n",
       " 'masterpiece': 972,\n",
       " 'joke': 973,\n",
       " '70s': 974,\n",
       " 'outside': 975,\n",
       " 'fire': 976,\n",
       " 'ideas': 977,\n",
       " 'missing': 978,\n",
       " 'jane': 979,\n",
       " 'reasons': 980,\n",
       " 'deserves': 981,\n",
       " 'twist': 982,\n",
       " 'match': 983,\n",
       " 'fantasy': 984,\n",
       " 'expecting': 985,\n",
       " 'dumb': 986,\n",
       " 'fairly': 987,\n",
       " 'secret': 988,\n",
       " 'la': 989,\n",
       " 'present': 990,\n",
       " 'manages': 991,\n",
       " 'air': 992,\n",
       " 'attempts': 993,\n",
       " 'political': 994,\n",
       " 'fighting': 995,\n",
       " 'gay': 996,\n",
       " 'success': 997,\n",
       " 'pay': 998,\n",
       " 'break': 999,\n",
       " 'unlike': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_dict = tokenizer.word_index\n",
    "\n",
    "word_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c3cefcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112530"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的words\n",
    "\n",
    "diff_words = len(tokenizer.word_index)\n",
    "\n",
    "diff_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "752b0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 word_embedding\n",
    "\n",
    "MAX_WORD = 20000 # 假设常见单词20000个\n",
    "EMBEDDING_DIM = 100 # 100维\n",
    "\n",
    "embedding_matrix = np.zeros((MAX_WORD, EMBEDDING_DIM)) # 初始化为全零向量\n",
    "\n",
    "for word, i in word_index_dict.items():\n",
    "    # 从glove中检索\n",
    "    word_embedding = embedding_dicts.get(word)\n",
    "    # 判断是否超过10000的基线\n",
    "    if i < MAX_WORD:\n",
    "        # 判断是否检索到embedding\n",
    "        if word_embedding is not None:\n",
    "            embedding_matrix[i] = word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8c3660a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.071953,  0.23127 ,  0.023731, -0.50638 ,  0.33923 ,  0.1959  ,\n",
       "       -0.32943 ,  0.18364 , -0.18057 ,  0.28963 ,  0.20448 , -0.5496  ,\n",
       "        0.27399 ,  0.58327 ,  0.20468 , -0.49228 ,  0.19974 , -0.070237,\n",
       "       -0.88049 ,  0.29485 ,  0.14071 , -0.1009  ,  0.99449 ,  0.36973 ,\n",
       "        0.44554 ,  0.28998 , -0.1376  , -0.56365 , -0.029365, -0.4122  ,\n",
       "       -0.25269 ,  0.63181 , -0.44767 ,  0.24363 , -0.10813 ,  0.25164 ,\n",
       "        0.46967 ,  0.3755  , -0.23613 , -0.14129 , -0.44537 , -0.65737 ,\n",
       "       -0.042421, -0.28636 , -0.28811 ,  0.063766,  0.20281 , -0.53542 ,\n",
       "        0.41307 , -0.59722 , -0.38614 ,  0.19389 , -0.17809 ,  1.6618  ,\n",
       "       -0.011819, -2.3737  ,  0.058427, -0.2698  ,  1.2823  ,  0.81925 ,\n",
       "       -0.22322 ,  0.72932 , -0.053211,  0.43507 ,  0.85011 , -0.42935 ,\n",
       "        0.92664 ,  0.39051 ,  1.0585  , -0.24561 , -0.18265 , -0.5328  ,\n",
       "        0.059518, -0.66019 ,  0.18991 ,  0.28836 , -0.2434  ,  0.52784 ,\n",
       "       -0.65762 , -0.14081 ,  1.0491  ,  0.5134  , -0.23816 ,  0.69895 ,\n",
       "       -1.4813  , -0.2487  , -0.17936 , -0.059137, -0.08056 , -0.48782 ,\n",
       "        0.014487, -0.6259  , -0.32367 ,  0.41862 , -1.0807  ,  0.46742 ,\n",
       "       -0.49931 , -0.71895 ,  0.86894 ,  0.19539 ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8dd669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建模型\n",
    "\n",
    "model = Sequential([\n",
    "    vectorize_layer, # 首先，对strings进行转换\n",
    "    Embedding(MAX_WORD, EMBEDDING_DIM, input_length=SEQ_LEN, weights=[embedding_matrix], trainable=False),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51de93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型编译\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab624702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.7090 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5008\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.6929 - acc: 0.4984 - val_loss: 0.6931 - val_acc: 0.5008\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.6911 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.4970\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.6874 - acc: 0.5123 - val_loss: 0.6932 - val_acc: 0.4992\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.6901 - acc: 0.5143 - val_loss: 0.6932 - val_acc: 0.4990\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.6930 - acc: 0.5027 - val_loss: 0.6932 - val_acc: 0.4990\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.4990\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.6931 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.4988\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.6931 - acc: 0.5013 - val_loss: 0.6932 - val_acc: 0.4972\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.6933 - acc: 0.5026 - val_loss: 0.6932 - val_acc: 0.4990\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.6931 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.4990\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.6931 - acc: 0.4961 - val_loss: 0.6931 - val_acc: 0.4990\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 0.6931 - acc: 0.4964 - val_loss: 0.6931 - val_acc: 0.5012\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.6931 - acc: 0.4969 - val_loss: 0.6931 - val_acc: 0.5012\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.6931 - acc: 0.4998 - val_loss: 0.6931 - val_acc: 0.5012\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.6931 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.5014\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.6927 - acc: 0.4988 - val_loss: 0.6932 - val_acc: 0.4992\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.6931 - acc: 0.5016 - val_loss: 0.6932 - val_acc: 0.4972\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.6915 - acc: 0.4992 - val_loss: 0.6885 - val_acc: 0.4990\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.6780 - acc: 0.5581 - val_loss: 0.6837 - val_acc: 0.5684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa884a9bb80>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "!rm -rf logs\n",
    "\n",
    "log_file = os.path.join('logs', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard = TensorBoard(log_file)\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=20,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8dfee109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8f0b139c683887bb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8f0b139c683887bb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bff35113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6837 - acc: 0.5684\n"
     ]
    }
   ],
   "source": [
    "# 模型验证\n",
    "\n",
    "loss, accuracy = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960c668",
   "metadata": {},
   "source": [
    "### 第6步：获取训练后的 word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c808bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 权重\n",
    "\n",
    "weights = model.get_layer(\"embedding\").get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4281d22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "133e84a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'in',\n",
       " 'it',\n",
       " 'i',\n",
       " 'this',\n",
       " 'that',\n",
       " 'was',\n",
       " 'as',\n",
       " 'with',\n",
       " 'for',\n",
       " 'movie',\n",
       " 'but',\n",
       " 'film',\n",
       " 'on',\n",
       " 'not',\n",
       " 'you',\n",
       " 'are',\n",
       " 'his',\n",
       " 'have',\n",
       " 'be',\n",
       " 'he',\n",
       " 'one',\n",
       " 'its',\n",
       " 'all',\n",
       " 'at',\n",
       " 'by',\n",
       " 'an',\n",
       " 'they',\n",
       " 'who',\n",
       " 'from',\n",
       " 'so',\n",
       " 'like',\n",
       " 'her',\n",
       " 'or',\n",
       " 'just',\n",
       " 'about',\n",
       " 'has',\n",
       " 'if',\n",
       " 'out',\n",
       " 'some',\n",
       " 'there',\n",
       " 'what',\n",
       " 'good',\n",
       " 'more',\n",
       " 'when',\n",
       " 'very',\n",
       " 'even',\n",
       " 'my',\n",
       " 'no',\n",
       " 'she',\n",
       " 'up',\n",
       " 'would',\n",
       " 'time',\n",
       " 'only',\n",
       " 'which',\n",
       " 'really',\n",
       " 'story',\n",
       " 'their',\n",
       " 'had',\n",
       " 'see',\n",
       " 'were',\n",
       " 'can',\n",
       " 'me',\n",
       " 'than',\n",
       " 'we',\n",
       " 'much',\n",
       " 'well',\n",
       " 'get',\n",
       " 'been',\n",
       " 'will',\n",
       " 'other',\n",
       " 'also',\n",
       " 'people',\n",
       " 'into',\n",
       " 'do',\n",
       " 'because',\n",
       " 'bad',\n",
       " 'great',\n",
       " 'him',\n",
       " 'first',\n",
       " 'most',\n",
       " 'how',\n",
       " 'dont',\n",
       " 'made',\n",
       " 'then',\n",
       " 'them',\n",
       " 'films',\n",
       " 'movies',\n",
       " 'way',\n",
       " 'make',\n",
       " 'too',\n",
       " 'could',\n",
       " 'any',\n",
       " 'after',\n",
       " 'characters',\n",
       " 'think',\n",
       " 'watch',\n",
       " 'many',\n",
       " 'seen',\n",
       " 'character',\n",
       " 'two',\n",
       " 'being',\n",
       " 'little',\n",
       " 'never',\n",
       " 'acting',\n",
       " 'plot',\n",
       " 'did',\n",
       " 'best',\n",
       " 'love',\n",
       " 'where',\n",
       " 'life',\n",
       " 'know',\n",
       " 'show',\n",
       " 'ever',\n",
       " 'does',\n",
       " 'better',\n",
       " 'your',\n",
       " 'over',\n",
       " 'off',\n",
       " 'still',\n",
       " 'end',\n",
       " 'here',\n",
       " 'scene',\n",
       " 'these',\n",
       " 'say',\n",
       " 'man',\n",
       " 'while',\n",
       " 'why',\n",
       " 'scenes',\n",
       " 'such',\n",
       " 'go',\n",
       " 'through',\n",
       " 'something',\n",
       " 'should',\n",
       " 'back',\n",
       " 'im',\n",
       " 'those',\n",
       " 'real',\n",
       " 'watching',\n",
       " 'doesnt',\n",
       " 'thing',\n",
       " 'years',\n",
       " 'now',\n",
       " 'actors',\n",
       " 'though',\n",
       " 'didnt',\n",
       " 'another',\n",
       " 'before',\n",
       " 'new',\n",
       " 'actually',\n",
       " 'nothing',\n",
       " 'funny',\n",
       " 'makes',\n",
       " 'work',\n",
       " 'look',\n",
       " 'going',\n",
       " 'few',\n",
       " 'find',\n",
       " 'old',\n",
       " 'same',\n",
       " 'part',\n",
       " 'us',\n",
       " 'every',\n",
       " 'again',\n",
       " 'lot',\n",
       " 'director',\n",
       " 'thats',\n",
       " 'cant',\n",
       " 'things',\n",
       " 'quite',\n",
       " 'cast',\n",
       " 'young',\n",
       " 'pretty',\n",
       " 'got',\n",
       " 'want',\n",
       " 'seems',\n",
       " 'down',\n",
       " 'around',\n",
       " 'world',\n",
       " 'fact',\n",
       " 'take',\n",
       " 'enough',\n",
       " 'give',\n",
       " 'however',\n",
       " 'may',\n",
       " 'horror',\n",
       " 'both',\n",
       " 'between',\n",
       " 'own',\n",
       " 'big',\n",
       " 'original',\n",
       " 'ive',\n",
       " 'always',\n",
       " 'thought',\n",
       " 'gets',\n",
       " 'times',\n",
       " 'without',\n",
       " 'right',\n",
       " 'long',\n",
       " 'isnt',\n",
       " 'come',\n",
       " 'series',\n",
       " 'role',\n",
       " 'almost',\n",
       " 'point',\n",
       " 'action',\n",
       " 'saw',\n",
       " 'theres',\n",
       " 'least',\n",
       " 'interesting',\n",
       " 'whole',\n",
       " 'family',\n",
       " 'bit',\n",
       " 'must',\n",
       " 'comedy',\n",
       " 'done',\n",
       " 'music',\n",
       " 'minutes',\n",
       " 'script',\n",
       " 'far',\n",
       " 'performance',\n",
       " 'might',\n",
       " 'since',\n",
       " 'anything',\n",
       " 'guy',\n",
       " 'last',\n",
       " 'feel',\n",
       " 'hes',\n",
       " 'probably',\n",
       " 'am',\n",
       " 'kind',\n",
       " 'away',\n",
       " 'rather',\n",
       " 'yet',\n",
       " 'worst',\n",
       " 'sure',\n",
       " 'making',\n",
       " 'woman',\n",
       " 'girl',\n",
       " 'fun',\n",
       " 'tv',\n",
       " 'each',\n",
       " 'found',\n",
       " 'played',\n",
       " 'anyone',\n",
       " 'course',\n",
       " 'day',\n",
       " 'although',\n",
       " 'having',\n",
       " 'comes',\n",
       " 'believe',\n",
       " 'our',\n",
       " 'goes',\n",
       " 'especially',\n",
       " 'different',\n",
       " 'trying',\n",
       " 'hard',\n",
       " 'looks',\n",
       " 'put',\n",
       " 'place',\n",
       " 'shows',\n",
       " 'book',\n",
       " 'wasnt',\n",
       " 'set',\n",
       " 'ending',\n",
       " 'maybe',\n",
       " 'once',\n",
       " 'money',\n",
       " 'everything',\n",
       " 'sense',\n",
       " 'someone',\n",
       " 'main',\n",
       " 'screen',\n",
       " 'true',\n",
       " 'looking',\n",
       " 'reason',\n",
       " 'plays',\n",
       " 'actor',\n",
       " 'worth',\n",
       " 'watched',\n",
       " 'job',\n",
       " 'said',\n",
       " 'later',\n",
       " 'beautiful',\n",
       " '2',\n",
       " 'takes',\n",
       " 'seem',\n",
       " 'play',\n",
       " 'version',\n",
       " 'together',\n",
       " 'dvd',\n",
       " 'himself',\n",
       " 'effects',\n",
       " '10',\n",
       " 'during',\n",
       " 'audience',\n",
       " 'night',\n",
       " 'john',\n",
       " 'three',\n",
       " 'instead',\n",
       " 'left',\n",
       " 'excellent',\n",
       " 'everyone',\n",
       " 'seeing',\n",
       " 'special',\n",
       " 'idea',\n",
       " 'house',\n",
       " 'american',\n",
       " 'shot',\n",
       " 'read',\n",
       " 'nice',\n",
       " 'wife',\n",
       " 'else',\n",
       " 'youre',\n",
       " 'less',\n",
       " 'simply',\n",
       " 'high',\n",
       " 'kids',\n",
       " 'war',\n",
       " 'help',\n",
       " 'completely',\n",
       " 'poor',\n",
       " 'used',\n",
       " 'year',\n",
       " 'friends',\n",
       " 'star',\n",
       " 'black',\n",
       " 'fan',\n",
       " 'father',\n",
       " 'mind',\n",
       " 'classic',\n",
       " 'given',\n",
       " 'home',\n",
       " 'second',\n",
       " 'rest',\n",
       " 'death',\n",
       " 'wrong',\n",
       " 'try',\n",
       " 'short',\n",
       " 'performances',\n",
       " 'use',\n",
       " 'men',\n",
       " 'either',\n",
       " 'along',\n",
       " 'hollywood',\n",
       " 'enjoy',\n",
       " 'boring',\n",
       " 'need',\n",
       " 'until',\n",
       " 'production',\n",
       " 'start',\n",
       " 'truly',\n",
       " 'dead',\n",
       " 'tell',\n",
       " 'line',\n",
       " 'women',\n",
       " 'came',\n",
       " 'moments',\n",
       " 'couple',\n",
       " 'next',\n",
       " 'stupid',\n",
       " 'perhaps',\n",
       " 'half',\n",
       " 'remember',\n",
       " 'mean',\n",
       " 'others',\n",
       " 'let',\n",
       " 'recommend',\n",
       " 'wonderful',\n",
       " 'awful',\n",
       " 'understand',\n",
       " 'full',\n",
       " 'playing',\n",
       " 'getting',\n",
       " 'episode',\n",
       " 'small',\n",
       " 'doing',\n",
       " 'terrible',\n",
       " 'keep',\n",
       " 'gives',\n",
       " 'camera',\n",
       " 'video',\n",
       " 'sex',\n",
       " 'stars',\n",
       " 'face',\n",
       " 'often',\n",
       " 'definitely',\n",
       " 'finally',\n",
       " 'lost',\n",
       " 'early',\n",
       " 'name',\n",
       " 'perfect',\n",
       " 'lines',\n",
       " 'itself',\n",
       " 'become',\n",
       " 'human',\n",
       " 'felt',\n",
       " 'couldnt',\n",
       " 'liked',\n",
       " 'piece',\n",
       " 'top',\n",
       " 'dialogue',\n",
       " 'yes',\n",
       " 'case',\n",
       " 'absolutely',\n",
       " 'entire',\n",
       " 'supposed',\n",
       " 'against',\n",
       " 'person',\n",
       " 'waste',\n",
       " 'title',\n",
       " 'style',\n",
       " 'school',\n",
       " 'live',\n",
       " 'budget',\n",
       " 'went',\n",
       " 'picture',\n",
       " 'head',\n",
       " 'certainly',\n",
       " 'written',\n",
       " 'cinema',\n",
       " 'shes',\n",
       " 'mr',\n",
       " 'worse',\n",
       " 'hope',\n",
       " 'problem',\n",
       " 'becomes',\n",
       " 'overall',\n",
       " 'several',\n",
       " 'beginning',\n",
       " 'entertaining',\n",
       " 'oh',\n",
       " 'evil',\n",
       " 'loved',\n",
       " 'id',\n",
       " 'fans',\n",
       " 'dark',\n",
       " 'white',\n",
       " 'sort',\n",
       " 'throughout',\n",
       " 'despite',\n",
       " 'care',\n",
       " 'already',\n",
       " 'lives',\n",
       " 'based',\n",
       " '3',\n",
       " 'mother',\n",
       " 'example',\n",
       " '\\x96',\n",
       " 'friend',\n",
       " 'direction',\n",
       " 'unfortunately',\n",
       " 'seemed',\n",
       " 'guys',\n",
       " 'boy',\n",
       " 'wanted',\n",
       " 'turn',\n",
       " 'killer',\n",
       " 'girls',\n",
       " 'final',\n",
       " 'wants',\n",
       " 'laugh',\n",
       " 'history',\n",
       " 'fine',\n",
       " 'lead',\n",
       " 'writing',\n",
       " 'children',\n",
       " 'amazing',\n",
       " 'drama',\n",
       " '1',\n",
       " 'totally',\n",
       " 'sound',\n",
       " 'called',\n",
       " 'wont',\n",
       " 'humor',\n",
       " 'low',\n",
       " 'youll',\n",
       " 'past',\n",
       " 'works',\n",
       " 'days',\n",
       " 'guess',\n",
       " 'michael',\n",
       " 'eyes',\n",
       " 'act',\n",
       " 'behind',\n",
       " 'theyre',\n",
       " 'son',\n",
       " 'quality',\n",
       " 'able',\n",
       " 'favorite',\n",
       " 'game',\n",
       " 'under',\n",
       " 'turns',\n",
       " 'tries',\n",
       " 'starts',\n",
       " 'side',\n",
       " 'flick',\n",
       " 'horrible',\n",
       " 'sometimes',\n",
       " 'enjoyed',\n",
       " 'kill',\n",
       " 'parts',\n",
       " 'town',\n",
       " 'soon',\n",
       " 'gave',\n",
       " 'viewer',\n",
       " 'themselves',\n",
       " 'ones',\n",
       " 'child',\n",
       " 'heart',\n",
       " 'expect',\n",
       " 'car',\n",
       " 'actress',\n",
       " 'genre',\n",
       " 'art',\n",
       " 'highly',\n",
       " 'thinking',\n",
       " 'stuff',\n",
       " 'brilliant',\n",
       " 'city',\n",
       " 'blood',\n",
       " 'stories',\n",
       " 'says',\n",
       " 'myself',\n",
       " 'obviously',\n",
       " 'fight',\n",
       " 'decent',\n",
       " 'feeling',\n",
       " 'directed',\n",
       " 'late',\n",
       " 'etc',\n",
       " 'hand',\n",
       " 'roles',\n",
       " 'moment',\n",
       " 'ill',\n",
       " 'strong',\n",
       " 'cannot',\n",
       " 'hell',\n",
       " 'close',\n",
       " 'heard',\n",
       " 'run',\n",
       " 'took',\n",
       " 'matter',\n",
       " 'except',\n",
       " 'killed',\n",
       " 'police',\n",
       " 'happens',\n",
       " 'involved',\n",
       " 'told',\n",
       " 'lack',\n",
       " 'chance',\n",
       " 'wouldnt',\n",
       " 'hour',\n",
       " 'leave',\n",
       " 'anyway',\n",
       " 'happened',\n",
       " 'age',\n",
       " 'kid',\n",
       " 'score',\n",
       " 'experience',\n",
       " 'attempt',\n",
       " 'voice',\n",
       " 'extremely',\n",
       " 'violence',\n",
       " 'obvious',\n",
       " 'happen',\n",
       " 'murder',\n",
       " 'shown',\n",
       " 'alone',\n",
       " 'living',\n",
       " 'wonder',\n",
       " 'complete',\n",
       " 'god',\n",
       " 'particularly',\n",
       " 'group',\n",
       " 'simple',\n",
       " 'looked',\n",
       " 'james',\n",
       " 'save',\n",
       " 'song',\n",
       " 'scary',\n",
       " 'exactly',\n",
       " 'daughter',\n",
       " 'type',\n",
       " 'please',\n",
       " 'coming',\n",
       " 'crap',\n",
       " 'slow',\n",
       " 'released',\n",
       " 'including',\n",
       " 'ago',\n",
       " 'none',\n",
       " 'interest',\n",
       " 'brother',\n",
       " 'possible',\n",
       " 'today',\n",
       " 'stop',\n",
       " 'annoying',\n",
       " 'across',\n",
       " 'lets',\n",
       " 'usual',\n",
       " 'known',\n",
       " 'career',\n",
       " 'whose',\n",
       " 'ok',\n",
       " 'yourself',\n",
       " 'usually',\n",
       " 'running',\n",
       " 'number',\n",
       " 'jokes',\n",
       " 'cut',\n",
       " 'taken',\n",
       " 'shots',\n",
       " 'somewhat',\n",
       " 'hours',\n",
       " 'body',\n",
       " 'serious',\n",
       " 'relationship',\n",
       " 'order',\n",
       " 'opening',\n",
       " 'hit',\n",
       " 'cinematography',\n",
       " 'cool',\n",
       " 'seriously',\n",
       " 'sad',\n",
       " 'ridiculous',\n",
       " 'ends',\n",
       " 'david',\n",
       " 'musical',\n",
       " 'saying',\n",
       " 'hilarious',\n",
       " 'gore',\n",
       " 'change',\n",
       " 'wish',\n",
       " 'robert',\n",
       " 'reality',\n",
       " 'novel',\n",
       " 'talking',\n",
       " 'english',\n",
       " 'started',\n",
       " 'rating',\n",
       " 'major',\n",
       " 'talent',\n",
       " 'huge',\n",
       " 'level',\n",
       " 'apparently',\n",
       " 'episodes',\n",
       " 'mostly',\n",
       " 'king',\n",
       " 'important',\n",
       " 'room',\n",
       " 'events',\n",
       " 'finds',\n",
       " 'view',\n",
       " 'easily',\n",
       " 'directors',\n",
       " 'power',\n",
       " 'opinion',\n",
       " 'due',\n",
       " 'taking',\n",
       " 'female',\n",
       " 'documentary',\n",
       " 'basically',\n",
       " 'words',\n",
       " 'silly',\n",
       " 'knows',\n",
       " 'sequence',\n",
       " 'hero',\n",
       " 'happy',\n",
       " 'call',\n",
       " 'arent',\n",
       " '4',\n",
       " 'strange',\n",
       " 'bring',\n",
       " 'supporting',\n",
       " 'word',\n",
       " 'turned',\n",
       " 'attention',\n",
       " 'songs',\n",
       " 'knew',\n",
       " 'disappointed',\n",
       " 'four',\n",
       " 'local',\n",
       " 'problems',\n",
       " 'five',\n",
       " 'clearly',\n",
       " 'british',\n",
       " 'husband',\n",
       " 'paul',\n",
       " 'cheap',\n",
       " 'tells',\n",
       " 'country',\n",
       " '5',\n",
       " 'review',\n",
       " 'whether',\n",
       " 'falls',\n",
       " 'single',\n",
       " 'whats',\n",
       " 'similar',\n",
       " 'sets',\n",
       " 'earth',\n",
       " 'future',\n",
       " 'jack',\n",
       " 'viewers',\n",
       " 'needs',\n",
       " 'richard',\n",
       " 'comic',\n",
       " 'beyond',\n",
       " 'modern',\n",
       " 'television',\n",
       " 'giving',\n",
       " 'enjoyable',\n",
       " 'appears',\n",
       " 'miss',\n",
       " 'light',\n",
       " 'theater',\n",
       " 'rock',\n",
       " 'bunch',\n",
       " 'predictable',\n",
       " 'george',\n",
       " 'feels',\n",
       " 'entertainment',\n",
       " 'within',\n",
       " 'nearly',\n",
       " 'lots',\n",
       " 'using',\n",
       " 'havent',\n",
       " 'points',\n",
       " 'surprised',\n",
       " 'named',\n",
       " 'actual',\n",
       " 'storyline',\n",
       " 'romantic',\n",
       " 'moving',\n",
       " 'lady',\n",
       " 'animation',\n",
       " 'message',\n",
       " 'mention',\n",
       " 'dull',\n",
       " 'upon',\n",
       " 'herself',\n",
       " 'begins',\n",
       " 'add',\n",
       " 'ways',\n",
       " 'theme',\n",
       " 'sequel',\n",
       " 'mystery',\n",
       " 'talk',\n",
       " 'ten',\n",
       " 'effort',\n",
       " 'above',\n",
       " 'middle',\n",
       " 'fantastic',\n",
       " 'among',\n",
       " 'york',\n",
       " 'avoid',\n",
       " 'thriller',\n",
       " 'french',\n",
       " 'stay',\n",
       " 'certain',\n",
       " 'easy',\n",
       " 'famous',\n",
       " 'typical',\n",
       " 'hate',\n",
       " 'straight',\n",
       " 'filmed',\n",
       " 'dialog',\n",
       " 'atmosphere',\n",
       " 'showing',\n",
       " 'check',\n",
       " 'writer',\n",
       " 'tried',\n",
       " 'means',\n",
       " 'leads',\n",
       " 'class',\n",
       " 'sorry',\n",
       " 'material',\n",
       " 'form',\n",
       " 'eye',\n",
       " 'clear',\n",
       " 'tale',\n",
       " 'somehow',\n",
       " 'red',\n",
       " 'fall',\n",
       " 'general',\n",
       " 'team',\n",
       " 'peter',\n",
       " 'greatest',\n",
       " 'soundtrack',\n",
       " 'buy',\n",
       " 'working',\n",
       " 'elements',\n",
       " 'whos',\n",
       " 'release',\n",
       " 'comments',\n",
       " 'weak',\n",
       " 'lee',\n",
       " 'space',\n",
       " 'oscar',\n",
       " 'feature',\n",
       " 'particular',\n",
       " 'figure',\n",
       " 'editing',\n",
       " 'realistic',\n",
       " 'period',\n",
       " 'parents',\n",
       " 'gone',\n",
       " 'learn',\n",
       " 'follow',\n",
       " 'season',\n",
       " 'near',\n",
       " 'brought',\n",
       " 'sister',\n",
       " 'move',\n",
       " 'doubt',\n",
       " 'viewing',\n",
       " 'kept',\n",
       " 'imagine',\n",
       " 'deal',\n",
       " 'youve',\n",
       " 'truth',\n",
       " 'hear',\n",
       " 'fast',\n",
       " 'stage',\n",
       " 'believable',\n",
       " 'wait',\n",
       " 'suspense',\n",
       " 'average',\n",
       " 'reviews',\n",
       " 'possibly',\n",
       " 'lame',\n",
       " 'sexual',\n",
       " 'decided',\n",
       " 'killing',\n",
       " 'screenplay',\n",
       " 'die',\n",
       " 'whatever',\n",
       " 'premise',\n",
       " 'indeed',\n",
       " 'eventually',\n",
       " 'became',\n",
       " 'tom',\n",
       " 'sequences',\n",
       " 'leaves',\n",
       " 'japanese',\n",
       " 'third',\n",
       " 'stand',\n",
       " 'sit',\n",
       " 'crime',\n",
       " 'okay',\n",
       " 'surprise',\n",
       " 'footage',\n",
       " 'dance',\n",
       " 'poorly',\n",
       " 'nature',\n",
       " 'otherwise',\n",
       " 'difficult',\n",
       " 'expected',\n",
       " 'rent',\n",
       " 'note',\n",
       " 'meets',\n",
       " 'filmmakers',\n",
       " 'subject',\n",
       " 'needed',\n",
       " 'writers',\n",
       " 'zombie',\n",
       " 'minute',\n",
       " 'nor',\n",
       " 'memorable',\n",
       " 'forget',\n",
       " 'de',\n",
       " '80s',\n",
       " 'weird',\n",
       " 'baby',\n",
       " 'question',\n",
       " 'street',\n",
       " 'situation',\n",
       " 'reading',\n",
       " 'credits',\n",
       " 'romance',\n",
       " 'realize',\n",
       " 'shame',\n",
       " 'forced',\n",
       " 'interested',\n",
       " 'features',\n",
       " 'dr',\n",
       " 'dramatic',\n",
       " 'comment',\n",
       " 'quickly',\n",
       " 'hot',\n",
       " 'brings',\n",
       " 'earlier',\n",
       " 'begin',\n",
       " 'boys',\n",
       " 'meet',\n",
       " 'emotional',\n",
       " 'hands',\n",
       " 'worked',\n",
       " 'dog',\n",
       " 'disney',\n",
       " 'write',\n",
       " 'keeps',\n",
       " 'directing',\n",
       " 'development',\n",
       " 'superb',\n",
       " 'beauty',\n",
       " 'various',\n",
       " 'setting',\n",
       " 'badly',\n",
       " 'sounds',\n",
       " 'america',\n",
       " 'whom',\n",
       " 'monster',\n",
       " 'mark',\n",
       " 'deep',\n",
       " 'crazy',\n",
       " 'joe',\n",
       " 'laughs',\n",
       " 'creepy',\n",
       " 'mess',\n",
       " 'towards',\n",
       " 'society',\n",
       " 'scifi',\n",
       " 'ask',\n",
       " 'perfectly',\n",
       " 'personal',\n",
       " 'older',\n",
       " 'effect',\n",
       " 'plus',\n",
       " 'b',\n",
       " 'apart',\n",
       " 'unless',\n",
       " 'plenty',\n",
       " 'cheesy',\n",
       " 'admit',\n",
       " 'result',\n",
       " 'remake',\n",
       " 'male',\n",
       " 'imdb',\n",
       " 'previous',\n",
       " 'incredibly',\n",
       " 'free',\n",
       " 'business',\n",
       " 'background',\n",
       " 'twist',\n",
       " 'casting',\n",
       " 'secret',\n",
       " 'open',\n",
       " 'return',\n",
       " 'hardly',\n",
       " 'unique',\n",
       " 'leading',\n",
       " 'present',\n",
       " 'total',\n",
       " 'meant',\n",
       " 'jane',\n",
       " 'outside',\n",
       " 'fails',\n",
       " 'appear',\n",
       " 'ideas',\n",
       " 'christmas',\n",
       " 'match',\n",
       " 'powerful',\n",
       " 'create',\n",
       " 'brothers',\n",
       " 'forward',\n",
       " 'dumb',\n",
       " 'reasons',\n",
       " 'portrayed',\n",
       " 'masterpiece',\n",
       " 'inside',\n",
       " '20',\n",
       " 'air',\n",
       " 'fire',\n",
       " 'ben',\n",
       " 'pay',\n",
       " 'fighting',\n",
       " 'battle',\n",
       " 'political',\n",
       " 'further',\n",
       " 'front',\n",
       " 'expecting',\n",
       " 'bill',\n",
       " 'william',\n",
       " 'missing',\n",
       " 'manages',\n",
       " 'deserves',\n",
       " 'joke',\n",
       " 'potential',\n",
       " 'unlike',\n",
       " 'rich',\n",
       " 'married',\n",
       " 'fairly',\n",
       " ...]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同的单词数量\n",
    "\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "\n",
    "vocab # 1000个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eeccad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存 weights 和 words\n",
    "\n",
    "out_v = io.open(\"weights.tsv\", 'w', encoding='utf-8')\n",
    "out_m = io.open(\"metadata.tsv\", 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "    if index == 0:\n",
    "        continue # 跳过第一个字符，这是padding\n",
    "    vec = weights[index] # 权重\n",
    "    # 写入\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "\n",
    "# 关闭文件\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d20ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
